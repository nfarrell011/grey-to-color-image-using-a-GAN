{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "899a665c-f384-4f94-84e0-263ef3da349e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output: (4, 1, 13, 13)\n",
      "Actual output: torch.Size([4, 1, 11, 11])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "\n",
    "import glob\n",
    "import yaml\n",
    "import torch\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from discriminator import *\n",
    "from generator import UNet\n",
    "from gan_utils_new import *\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress specific warning related to CIE-LAB conversion\n",
    "warnings.filterwarnings(\"ignore\", message=\".*negative Z values that have been clipped to zero.*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd24df06-c4db-472a-adfd-4bcebe9cd266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install fastai==2.4\n",
    "from fastai.vision.learner import create_body\n",
    "from torchvision.models.resnet import resnet18\n",
    "from fastai.vision.models.unet import DynamicUnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67f1244b-5e79-46a1-885f-da3ba144a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_res_unet(n_input=1, n_output=2, size=256):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    body = create_body(resnet18, pretrained=True, n_in=n_input, cut=-2)\n",
    "    net_G = DynamicUnet(body, n_output, (size, size)).to(device)\n",
    "    return net_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebb14a1-4c2a-449c-9a1d-a0dc65bca4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/farrell.jo/miniconda3/envs/GAN_env_CUDA11_8/lib/python3.9/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Weights Loaded!!!\n",
      "Optimizer states loaded successfully!\n",
      "\n",
      "========== Epoch 1/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/200: 100%|██████████| 500/500 [12:06<00:00,  1.45s/it, D_loss=0.626, G_loss=5.21]\n",
      "Validation Epoch 1/200: 100%|██████████| 125/125 [01:07<00:00,  1.86it/s, D_loss=0.705, G_loss=15.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/pretrained_gen_200_3/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 2/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/200: 100%|██████████| 500/500 [07:15<00:00,  1.15it/s, D_loss=0.629, G_loss=5.19]\n",
      "Validation Epoch 2/200: 100%|██████████| 125/125 [00:50<00:00,  2.45it/s, D_loss=0.707, G_loss=15.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/pretrained_gen_200_3/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 3/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/200: 100%|██████████| 500/500 [04:52<00:00,  1.71it/s, D_loss=0.628, G_loss=5.24]\n",
      "Validation Epoch 3/200: 100%|██████████| 125/125 [00:50<00:00,  2.50it/s, D_loss=0.708, G_loss=15.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/pretrained_gen_200_3/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 4/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/200: 100%|██████████| 500/500 [04:49<00:00,  1.72it/s, D_loss=0.627, G_loss=5.23]\n",
      "Validation Epoch 4/200: 100%|██████████| 125/125 [00:49<00:00,  2.54it/s, D_loss=0.71, G_loss=15.6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/pretrained_gen_200_3/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 5/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/200: 100%|██████████| 500/500 [04:46<00:00,  1.74it/s, D_loss=0.628, G_loss=5.23]\n",
      "Validation Epoch 5/200: 100%|██████████| 125/125 [00:47<00:00,  2.62it/s, D_loss=0.709, G_loss=15.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/pretrained_gen_200_3/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 6/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/200: 100%|██████████| 500/500 [04:50<00:00,  1.72it/s, D_loss=0.624, G_loss=5.23]\n",
      "Validation Epoch 6/200: 100%|██████████| 125/125 [00:47<00:00,  2.65it/s, D_loss=0.711, G_loss=15.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/pretrained_gen_200_3/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 7/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/200: 100%|██████████| 500/500 [05:16<00:00,  1.58it/s, D_loss=0.623, G_loss=5.28]\n",
      "Validation Epoch 7/200: 100%|██████████| 125/125 [00:52<00:00,  2.37it/s, D_loss=0.712, G_loss=15.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/pretrained_gen_200_3/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 8/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/200: 100%|██████████| 500/500 [04:59<00:00,  1.67it/s, D_loss=0.622, G_loss=5.24]\n",
      "Validation Epoch 8/200: 100%|██████████| 125/125 [00:50<00:00,  2.49it/s, D_loss=0.712, G_loss=15.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/pretrained_gen_200_3/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 9/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/200: 100%|██████████| 500/500 [04:51<00:00,  1.72it/s, D_loss=0.628, G_loss=5.23]\n",
      "Validation Epoch 9/200: 100%|██████████| 125/125 [00:51<00:00,  2.42it/s, D_loss=0.712, G_loss=15.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/pretrained_gen_200_3/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 10/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/200: 100%|██████████| 500/500 [04:45<00:00,  1.75it/s, D_loss=0.627, G_loss=5.24]\n",
      "Validation Epoch 10/200: 100%|██████████| 125/125 [00:46<00:00,  2.71it/s, D_loss=0.712, G_loss=15.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/pretrained_gen_200_3/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 11/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/200: 100%|██████████| 500/500 [05:24<00:00,  1.54it/s, D_loss=0.624, G_loss=5.26]\n",
      "Validation Epoch 11/200: 100%|██████████| 125/125 [00:56<00:00,  2.22it/s, D_loss=0.712, G_loss=15.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/pretrained_gen_200_3/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 12/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/200: 100%|██████████| 500/500 [05:03<00:00,  1.65it/s, D_loss=0.629, G_loss=5.23]\n",
      "Validation Epoch 12/200: 100%|██████████| 125/125 [00:51<00:00,  2.41it/s, D_loss=0.712, G_loss=15.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/pretrained_gen_200_3/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 13/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/200: 100%|██████████| 500/500 [05:16<00:00,  1.58it/s, D_loss=0.631, G_loss=5.25]\n",
      "Validation Epoch 13/200: 100%|██████████| 125/125 [00:51<00:00,  2.42it/s, D_loss=0.712, G_loss=15.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/pretrained_gen_200_3/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 14/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14/200: 100%|██████████| 500/500 [05:06<00:00,  1.63it/s, D_loss=0.628, G_loss=5.23]\n",
      "Validation Epoch 14/200: 100%|██████████| 125/125 [00:52<00:00,  2.38it/s, D_loss=0.712, G_loss=15.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/pretrained_gen_200_3/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 15/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15/200: 100%|██████████| 500/500 [04:59<00:00,  1.67it/s, D_loss=0.622, G_loss=5.28]\n",
      "Validation Epoch 15/200: 100%|██████████| 125/125 [00:45<00:00,  2.74it/s, D_loss=0.713, G_loss=15.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/pretrained_gen_200_3/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 16/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16/200: 100%|██████████| 500/500 [05:57<00:00,  1.40it/s, D_loss=0.629, G_loss=5.24]\n",
      "Validation Epoch 16/200: 100%|██████████| 125/125 [00:48<00:00,  2.56it/s, D_loss=0.711, G_loss=15.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/pretrained_gen_200_3/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 17/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17/200: 100%|██████████| 500/500 [04:47<00:00,  1.74it/s, D_loss=0.627, G_loss=5.24]\n",
      "Validation Epoch 17/200: 100%|██████████| 125/125 [00:50<00:00,  2.50it/s, D_loss=0.712, G_loss=15.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/pretrained_gen_200_3/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 18/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18/200: 100%|██████████| 500/500 [04:53<00:00,  1.71it/s, D_loss=0.627, G_loss=5.26]\n",
      "Validation Epoch 18/200: 100%|██████████| 125/125 [00:48<00:00,  2.59it/s, D_loss=0.712, G_loss=15.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/pretrained_gen_200_3/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 19/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19/200: 100%|██████████| 500/500 [05:16<00:00,  1.58it/s, D_loss=0.624, G_loss=5.23]\n",
      "Validation Epoch 19/200: 100%|██████████| 125/125 [00:47<00:00,  2.62it/s, D_loss=0.712, G_loss=15.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/pretrained_gen_200_3/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 20/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20/200: 100%|██████████| 500/500 [04:43<00:00,  1.76it/s, D_loss=0.629, G_loss=5.25]\n",
      "Validation Epoch 20/200: 100%|██████████| 125/125 [00:46<00:00,  2.68it/s, D_loss=0.712, G_loss=15.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/pretrained_gen_200_3/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 21/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21/200: 100%|██████████| 500/500 [05:15<00:00,  1.59it/s, D_loss=0.628, G_loss=5.27]\n",
      "Validation Epoch 21/200: 100%|██████████| 125/125 [00:53<00:00,  2.34it/s, D_loss=0.712, G_loss=15.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/pretrained_gen_200_3/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 22/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22/200: 100%|██████████| 500/500 [05:32<00:00,  1.50it/s, D_loss=0.627, G_loss=5.22]\n",
      "Validation Epoch 22/200: 100%|██████████| 125/125 [00:49<00:00,  2.55it/s, D_loss=0.712, G_loss=15.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/pretrained_gen_200_3/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 23/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23/200: 100%|██████████| 500/500 [06:31<00:00,  1.28it/s, D_loss=0.628, G_loss=5.27]\n",
      "Validation Epoch 23/200: 100%|██████████| 125/125 [00:51<00:00,  2.43it/s, D_loss=0.712, G_loss=15.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/pretrained_gen_200_3/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 24/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24/200: 100%|██████████| 500/500 [09:02<00:00,  1.09s/it, D_loss=0.63, G_loss=5.26] \n",
      "Validation Epoch 24/200:   2%|▏         | 3/125 [00:04<03:34,  1.76s/it, D_loss=0.703, G_loss=14.7]"
     ]
    }
   ],
   "source": [
    "# Function to load configuration from YAML file\n",
    "def load_config(config_path='params.yaml'):\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "# Function to select optimizer\n",
    "def get_optimizer(optimizer_config, model_params):\n",
    "    opt_type = optimizer_config['type']\n",
    "    lr = optimizer_config['lr']\n",
    "\n",
    "    if opt_type == \"Adam\":\n",
    "        beta1 = optimizer_config['beta1']\n",
    "        beta2 = optimizer_config['beta2']\n",
    "        optimizer = torch.optim.Adam(model_params, lr=lr, betas=(beta1, beta2))\n",
    "\n",
    "    elif opt_type == \"SGD\":\n",
    "        momentum = optimizer_config['momentum']\n",
    "        optimizer = torch.optim.SGD(model_params, lr=lr, momentum=momentum)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Optimizer type '{opt_type}' not recognized. Please choose 'Adam' or 'SGD'.\")\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Load the configuration from YAML\n",
    "    load_states = True\n",
    "    load_gen_weights = False\n",
    "    config = load_config()\n",
    "    \n",
    "    # Set up logging\n",
    "    logging.basicConfig(filename=f\"{config['output']['run_dir']}training.log\", level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "\n",
    "    # Setup device (GPU/CPU)\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"Cuda is available!\")\n",
    "        logging.info(\"CUDA is available. Using GPU.\")\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        logging.info(\"CUDA is not available. Using CPU.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(f\"Unable to connect to CUDA!!!!\")\n",
    "\n",
    "    # File path from YAML\n",
    "    coco_path = config['data']['coco_path']\n",
    "    paths = glob.glob(coco_path + \"/*.jpg\")  # Grabbing all the image file names\n",
    "\n",
    "    # Load number of images from config\n",
    "    num_imgs = config['data']['num_imgs']\n",
    "    split = config['data']['split']\n",
    "    train_paths, val_paths = select_images(paths, num_imgs, split)\n",
    "    logging.info(f\"Training set: {len(train_paths)} images\")\n",
    "    logging.info(f\"Validation set: {len(val_paths)} images\")\n",
    "\n",
    "    # Image size from YAML\n",
    "    size = config['data']['image_size']\n",
    "    train_ds = ColorizationDataset(size, paths=train_paths, split=\"train\")\n",
    "    val_ds = ColorizationDataset(size, paths=val_paths, split=\"val\")\n",
    "\n",
    "    # Batch size from YAML\n",
    "    batch_size = config['training']['batch_size']\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size)\n",
    "    val_dl = DataLoader(val_ds, batch_size=batch_size)\n",
    "\n",
    "    # Check Tensor Size\n",
    "    data = next(iter(train_dl))\n",
    "    Ls, abs_ = data['L'], data['ab']\n",
    "    assert Ls.shape == torch.Size([batch_size, 1, size, size]) and abs_.shape == torch.Size([batch_size, 2, size, size])\n",
    "\n",
    "    # Model parameters\n",
    "    generator = build_res_unet()\n",
    "    discriminator = PatchDiscriminator(3)\n",
    "\n",
    "    # Create the model initializer\n",
    "    initializer = ModelInitializer(device, init_type=config['model']['init_type'], gain=config['model']['gain'])\n",
    "        \n",
    "    # Initialize the models\n",
    "    if load_states:\n",
    "        try:\n",
    "            # Load the model checkpoints\n",
    "            checkpoint = torch.load(\"/home/farrell.jo/cGAN_grey_to_color/models/training_runs/pretrained_gen_200_2/model_weights/checkpoint.pth\")\n",
    "            generator.load_state_dict(checkpoint[\"generator_state_dict\"])\n",
    "            discriminator.load_state_dict(checkpoint[\"discriminator_state_dict\"])\n",
    "            print(\"Previous Weights Loaded!!!\")\n",
    "        except FileNotFoundError as e:\n",
    "            print(\"Error loading model weights!\")\n",
    "            \n",
    "    elif load_gen_weights:\n",
    "        try:\n",
    "            # Load the model checkpoints\n",
    "            checkpoint = torch.load(\"/home/farrell.jo/cGAN_grey_to_color/models/generator_train/Res_full_data_1/gen_weights/checkpoint_epoch_20.pth\")\n",
    "            generator.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "            discriminator = initializer.init_model(discriminator)\n",
    "            print(f\"Generator weights laoded successfully!\")\n",
    "        except FileNotFoundError as e:\n",
    "            print(\"Error loadinf generator weights!\")\n",
    "            \n",
    "    else:\n",
    "        generator = initializer.init_model(generator)\n",
    "        discriminator = initializer.init_model(discriminator)\n",
    "        print(f\"Models initialized!\")\n",
    "\n",
    "    # Move models to device (GPU/CPU)\n",
    "    generator.to(device)\n",
    "    discriminator.to(device)\n",
    "\n",
    "    # Loss functions from YAML\n",
    "    adversarial_loss = nn.BCEWithLogitsLoss()\n",
    "    content_loss = nn.L1Loss()   \n",
    "    lambda_l1 = config['training']['lambda_l1']\n",
    "\n",
    "    # Get optimizer from YAML configuration for both generator and discriminator\n",
    "    optimizer_G = get_optimizer(config['optimizer_G'], generator.parameters())\n",
    "    optimizer_D = get_optimizer(config['optimizer_D'], discriminator.parameters())\n",
    "\n",
    "    # Load optimizer state if available in checkpoint\n",
    "    if load_states:\n",
    "        if 'optimizer_gen_state_dict' in checkpoint and 'optimizer_disc_state_dict' in checkpoint:\n",
    "            optimizer_G.load_state_dict(checkpoint['optimizer_gen_state_dict'])\n",
    "            optimizer_D.load_state_dict(checkpoint['optimizer_disc_state_dict'])\n",
    "            print(\"Optimizer states loaded successfully!\")\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    mode = config['scheduler_G']['mode']\n",
    "    factor = config['scheduler_G']['factor']\n",
    "    patience = config['scheduler_G']['patience']\n",
    "    verbose = config['scheduler_G']['verbose']\n",
    "    scheduler_G = optim.lr_scheduler.ReduceLROnPlateau(optimizer_G, mode, factor, patience, verbose)\n",
    "\n",
    "    mode = config['scheduler_D']['mode']\n",
    "    factor = config['scheduler_D']['factor']\n",
    "    patience = config['scheduler_D']['patience']\n",
    "    verbose = config['scheduler_D']['verbose']\n",
    "    scheduler_D = optim.lr_scheduler.ReduceLROnPlateau(optimizer_D, mode, factor, patience, verbose)\n",
    "\n",
    "    # Number of epochs from YAML\n",
    "    epochs = config['training']['epochs']\n",
    "\n",
    "    # Flags for showing and saving images\n",
    "    show_fig = config['training']['show_fig']\n",
    "    save_images = config['training']['save_images']\n",
    "\n",
    "    # Initialize GANDriver with all parameters from YAML\n",
    "    driver = GANDriver(\n",
    "        generator=generator,\n",
    "        discriminator=discriminator,\n",
    "        train_dl=train_dl,\n",
    "        val_dl=val_dl,\n",
    "        optimizer_G=optimizer_G,\n",
    "        optimizer_D=optimizer_D,\n",
    "        adversarial_loss=adversarial_loss,\n",
    "        content_loss=content_loss,\n",
    "        lambda_l1=lambda_l1,\n",
    "        device=device,\n",
    "        epochs=epochs,\n",
    "        scheduler_D=scheduler_D, \n",
    "        scheduler_G=scheduler_G,\n",
    "        run_dir=config['output']['run_dir'],\n",
    "        base_dir=config['output']['base_dir']\n",
    "    )\n",
    "\n",
    "    # Run the GAN training and save metrics to CSV after each epoch\n",
    "    train_results = driver.run(show_fig=show_fig, save_images=save_images)\n",
    "\n",
    "    # Save training results to CSV\n",
    "    results_df = pd.DataFrame(train_results)\n",
    "    result_path = f\"{config['output']['base_dir']}/{config['output']['run_dir']}/{config['output']['training_results_csv']}\"\n",
    "    results_df.to_csv(result_path, index=False)\n",
    "    logging.info(f\"Training complete. Results saved to {result_path}.\")\n",
    "\n",
    "    \n",
    "    # Save the dictionary to a YAML file\n",
    "    yaml_filepath = f\"{config['output']['base_dir']}/{config['output']['run_dir']}/config.yml\"\n",
    "    with open(yaml_filepath, 'w') as file:\n",
    "        yaml.dump(config, file, default_flow_style=False)\n",
    "    \n",
    "    logging.info(f\"Configuration saved to {yaml_filepath}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18361e2b-3410-43f8-9a98-064164e95632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b9efdd-3fea-49a0-a33e-1c9bbe724c60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
