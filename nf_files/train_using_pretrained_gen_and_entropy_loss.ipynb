{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eedcd661-402e-4432-85ae-3ade513339ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output: (4, 1, 13, 13)\n",
      "Actual output: torch.Size([4, 1, 11, 11])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "import glob\n",
    "import yaml\n",
    "import torch\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from discriminator import *\n",
    "from generator import UNet\n",
    "from gan_utils_new import *\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress specific warning related to CIE-LAB conversion\n",
    "warnings.filterwarnings(\"ignore\", message=\".*negative Z values that have been clipped to zero.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1892379b-db6d-4892-b9e7-bded2d6a65af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install fastai==2.4\n",
    "from fastai.vision.learner import create_body\n",
    "from torchvision.models.resnet import resnet18\n",
    "from fastai.vision.models.unet import DynamicUnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc4cffce-d3e1-46bc-bb1f-ccc6fd162ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_res_unet(n_input=1, n_output=2, size=256):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    body = create_body(resnet18, pretrained=True, n_in=n_input, cut=-2)\n",
    "    net_G = DynamicUnet(body, n_output, (size, size)).to(device)\n",
    "    return net_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1a18b9-558e-4856-844c-3e4a7fb22e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/farrell.jo/miniconda3/envs/GAN_env_CUDA11_8/lib/python3.9/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models initialized!\n",
      "\n",
      "========== Epoch 1/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/200: 100%|██████████| 125/125 [03:52<00:00,  1.86s/it, D_loss=0.345, G_loss=18.9]\n",
      "Validation Epoch 1/200: 100%|██████████| 32/32 [00:47<00:00,  1.50s/it, D_loss=0.845, G_loss=18.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 2/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/200: 100%|██████████| 125/125 [03:25<00:00,  1.64s/it, D_loss=0.407, G_loss=20.5]\n",
      "Validation Epoch 2/200: 100%|██████████| 32/32 [00:42<00:00,  1.31s/it, D_loss=0.812, G_loss=23.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 3/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/200: 100%|██████████| 125/125 [03:25<00:00,  1.65s/it, D_loss=0.233, G_loss=21.5]\n",
      "Validation Epoch 3/200: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it, D_loss=0.848, G_loss=19.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 4/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/200: 100%|██████████| 125/125 [03:26<00:00,  1.65s/it, D_loss=0.301, G_loss=21]  \n",
      "Validation Epoch 4/200: 100%|██████████| 32/32 [00:41<00:00,  1.29s/it, D_loss=0.772, G_loss=19.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 5/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/200: 100%|██████████| 125/125 [03:35<00:00,  1.73s/it, D_loss=0.295, G_loss=20.8]\n",
      "Validation Epoch 5/200: 100%|██████████| 32/32 [00:47<00:00,  1.48s/it, D_loss=0.733, G_loss=20.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 6/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/200: 100%|██████████| 125/125 [03:42<00:00,  1.78s/it, D_loss=0.378, G_loss=20.2]\n",
      "Validation Epoch 6/200: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it, D_loss=0.735, G_loss=19.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 7/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/200: 100%|██████████| 125/125 [03:27<00:00,  1.66s/it, D_loss=0.327, G_loss=20]  \n",
      "Validation Epoch 7/200: 100%|██████████| 32/32 [00:42<00:00,  1.34s/it, D_loss=0.684, G_loss=21.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 8/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/200: 100%|██████████| 125/125 [03:26<00:00,  1.66s/it, D_loss=0.293, G_loss=19.3]\n",
      "Validation Epoch 8/200: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it, D_loss=0.694, G_loss=20.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 9/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/200: 100%|██████████| 125/125 [03:27<00:00,  1.66s/it, D_loss=0.347, G_loss=18.8]\n",
      "Validation Epoch 9/200: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it, D_loss=0.655, G_loss=18.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 10/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/200: 100%|██████████| 125/125 [03:31<00:00,  1.69s/it, D_loss=0.368, G_loss=18.8]\n",
      "Validation Epoch 10/200: 100%|██████████| 32/32 [00:42<00:00,  1.34s/it, D_loss=0.641, G_loss=18.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 11/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/200: 100%|██████████| 125/125 [03:40<00:00,  1.76s/it, D_loss=0.386, G_loss=18.7]\n",
      "Validation Epoch 11/200: 100%|██████████| 32/32 [00:44<00:00,  1.40s/it, D_loss=0.642, G_loss=18.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 12/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/200: 100%|██████████| 125/125 [03:34<00:00,  1.71s/it, D_loss=0.42, G_loss=18.4] \n",
      "Validation Epoch 12/200: 100%|██████████| 32/32 [00:44<00:00,  1.38s/it, D_loss=0.643, G_loss=19.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 13/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/200: 100%|██████████| 125/125 [03:41<00:00,  1.77s/it, D_loss=0.386, G_loss=18]  \n",
      "Validation Epoch 13/200: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it, D_loss=0.638, G_loss=19.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 14/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14/200: 100%|██████████| 125/125 [03:47<00:00,  1.82s/it, D_loss=0.366, G_loss=17.6]\n",
      "Validation Epoch 14/200: 100%|██████████| 32/32 [00:43<00:00,  1.36s/it, D_loss=0.641, G_loss=19.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 15/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15/200: 100%|██████████| 125/125 [03:32<00:00,  1.70s/it, D_loss=0.37, G_loss=17.3] \n",
      "Validation Epoch 15/200: 100%|██████████| 32/32 [00:43<00:00,  1.36s/it, D_loss=0.64, G_loss=19]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 16/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16/200: 100%|██████████| 125/125 [03:29<00:00,  1.67s/it, D_loss=0.382, G_loss=16.9]\n",
      "Validation Epoch 16/200: 100%|██████████| 32/32 [00:40<00:00,  1.28s/it, D_loss=0.63, G_loss=19.3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 17/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17/200: 100%|██████████| 125/125 [03:28<00:00,  1.66s/it, D_loss=0.368, G_loss=16.9]\n",
      "Validation Epoch 17/200: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it, D_loss=0.635, G_loss=19.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 18/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18/200: 100%|██████████| 125/125 [03:31<00:00,  1.69s/it, D_loss=0.365, G_loss=16.4]\n",
      "Validation Epoch 18/200: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it, D_loss=0.634, G_loss=18.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 19/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19/200: 100%|██████████| 125/125 [03:31<00:00,  1.69s/it, D_loss=0.361, G_loss=15.9]\n",
      "Validation Epoch 19/200: 100%|██████████| 32/32 [00:44<00:00,  1.40s/it, D_loss=0.634, G_loss=19.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 20/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20/200: 100%|██████████| 125/125 [03:39<00:00,  1.76s/it, D_loss=0.375, G_loss=15.8]\n",
      "Validation Epoch 20/200: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it, D_loss=0.638, G_loss=19.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 21/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21/200: 100%|██████████| 125/125 [03:33<00:00,  1.71s/it, D_loss=0.364, G_loss=15.8]\n",
      "Validation Epoch 21/200: 100%|██████████| 32/32 [00:44<00:00,  1.38s/it, D_loss=0.636, G_loss=19.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 22/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22/200: 100%|██████████| 125/125 [03:26<00:00,  1.65s/it, D_loss=0.352, G_loss=15.8]\n",
      "Validation Epoch 22/200: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it, D_loss=0.636, G_loss=19.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 23/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23/200: 100%|██████████| 125/125 [03:26<00:00,  1.65s/it, D_loss=0.351, G_loss=15.8]\n",
      "Validation Epoch 23/200: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it, D_loss=0.636, G_loss=19.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 24/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24/200: 100%|██████████| 125/125 [03:30<00:00,  1.68s/it, D_loss=0.357, G_loss=15.8]\n",
      "Validation Epoch 24/200: 100%|██████████| 32/32 [00:42<00:00,  1.33s/it, D_loss=0.639, G_loss=19.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 25/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25/200: 100%|██████████| 125/125 [03:29<00:00,  1.68s/it, D_loss=0.347, G_loss=16]  \n",
      "Validation Epoch 25/200: 100%|██████████| 32/32 [00:41<00:00,  1.30s/it, D_loss=0.634, G_loss=19.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 26/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26/200: 100%|██████████| 125/125 [03:30<00:00,  1.68s/it, D_loss=0.355, G_loss=15.6]\n",
      "Validation Epoch 26/200: 100%|██████████| 32/32 [00:45<00:00,  1.41s/it, D_loss=0.632, G_loss=19.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 27/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27/200: 100%|██████████| 125/125 [03:35<00:00,  1.73s/it, D_loss=0.346, G_loss=15.6]\n",
      "Validation Epoch 27/200: 100%|██████████| 32/32 [00:43<00:00,  1.35s/it, D_loss=0.634, G_loss=19.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 28/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 28/200: 100%|██████████| 125/125 [03:40<00:00,  1.76s/it, D_loss=0.356, G_loss=15.6]\n",
      "Validation Epoch 28/200: 100%|██████████| 32/32 [00:42<00:00,  1.32s/it, D_loss=0.633, G_loss=19.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 29/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29/200: 100%|██████████| 125/125 [03:25<00:00,  1.64s/it, D_loss=0.353, G_loss=15.4]\n",
      "Validation Epoch 29/200: 100%|██████████| 32/32 [00:41<00:00,  1.29s/it, D_loss=0.629, G_loss=19]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state saved to training_runs/base_model/model_weights/checkpoint.pth\n",
      "\n",
      "Training complete and model weights saved.\n",
      "\n",
      "========== Epoch 30/200 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30/200:  99%|█████████▉| 124/125 [03:25<00:01,  1.62s/it, D_loss=0.504, G_loss=15.1]"
     ]
    }
   ],
   "source": [
    "# Function to load configuration from YAML file\n",
    "def load_config(config_path='params.yaml'):\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "# Function to select optimizer\n",
    "def get_optimizer(optimizer_config, model_params):\n",
    "    opt_type = optimizer_config['type']\n",
    "    lr = optimizer_config['lr']\n",
    "\n",
    "    if opt_type == \"Adam\":\n",
    "        beta1 = optimizer_config['beta1']\n",
    "        beta2 = optimizer_config['beta2']\n",
    "        optimizer = torch.optim.Adam(model_params, lr=lr, betas=(beta1, beta2))\n",
    "\n",
    "    elif opt_type == \"SGD\":\n",
    "        momentum = optimizer_config['momentum']\n",
    "        optimizer = torch.optim.SGD(model_params, lr=lr, momentum=momentum)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Optimizer type '{opt_type}' not recognized. Please choose 'Adam' or 'SGD'.\")\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Load the configuration from YAML\n",
    "    load_states = False\n",
    "    load_gen_weights = False\n",
    "    config = load_config(\"params_2.yaml\")\n",
    "    \n",
    "    # Set up logging\n",
    "    logging.basicConfig(filename=f\"{config['output']['run_dir']}training.log\", level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "\n",
    "    # Setup device (GPU/CPU)\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"Cuda is available!\")\n",
    "        logging.info(\"CUDA is available. Using GPU.\")\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        logging.info(\"CUDA is not available. Using CPU.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(f\"Unable to connect to CUDA!!!!\")\n",
    "\n",
    "    # File path from YAML\n",
    "    coco_path = config['data']['coco_path']\n",
    "    paths = glob.glob(coco_path + \"/*.jpg\")  # Grabbing all the image file names\n",
    "\n",
    "    # Load number of images from config\n",
    "    num_imgs = config['data']['num_imgs']\n",
    "    split = config['data']['split']\n",
    "    train_paths, val_paths = select_images(paths, num_imgs, split)\n",
    "    logging.info(f\"Training set: {len(train_paths)} images\")\n",
    "    logging.info(f\"Validation set: {len(val_paths)} images\")\n",
    "\n",
    "    # Image size from YAML\n",
    "    size = config['data']['image_size']\n",
    "    train_ds = ColorizationDataset(size, paths=train_paths, split=\"train\")\n",
    "    val_ds = ColorizationDataset(size, paths=val_paths, split=\"val\")\n",
    "\n",
    "    # Batch size from YAML\n",
    "    batch_size = config['training']['batch_size']\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size)\n",
    "    val_dl = DataLoader(val_ds, batch_size=batch_size)\n",
    "\n",
    "    # Check Tensor Size\n",
    "    data = next(iter(train_dl))\n",
    "    Ls, abs_ = data['L'], data['ab']\n",
    "    assert Ls.shape == torch.Size([batch_size, 1, size, size]) and abs_.shape == torch.Size([batch_size, 2, size, size])\n",
    "\n",
    "    # Model parameters\n",
    "    generator = Unet()\n",
    "    discriminator = PatchDiscriminator(3)\n",
    "\n",
    "    # Create the model initializer\n",
    "    initializer = ModelInitializer(device, init_type=config['model']['init_type'], gain=config['model']['gain'])\n",
    "        \n",
    "    # Initialize the models\n",
    "    if load_states:\n",
    "        try:\n",
    "            # Load the model checkpoints\n",
    "            checkpoint = torch.load(\"/home/farrell.jo/cGAN_grey_to_color/models/training_runs/pretrained_gen_200_with_entropy_loss/model_weights/checkpoint.pth\")\n",
    "            generator.load_state_dict(checkpoint[\"generator_state_dict\"])\n",
    "            discriminator.load_state_dict(checkpoint[\"discriminator_state_dict\"])\n",
    "            print(\"Previous Weights Loaded!!!\")\n",
    "        except FileNotFoundError as e:\n",
    "            print(\"Error loading model weights!\")\n",
    "            \n",
    "    elif load_gen_weights:\n",
    "        try:\n",
    "            # Load the model checkpoints\n",
    "            checkpoint = torch.load(\"/home/farrell.jo/cGAN_grey_to_color/models/generator_train/Res_full_data_3/gen_weights/checkpoint_epoch_201.pth\")\n",
    "            generator.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "            discriminator = initializer.init_model(discriminator)\n",
    "            print(f\"Generator weights laoded successfully!\")\n",
    "        except FileNotFoundError as e:\n",
    "            print(\"Error loadinf generator weights!\")\n",
    "            \n",
    "    else:\n",
    "        generator = initializer.init_model(generator)\n",
    "        discriminator = initializer.init_model(discriminator)\n",
    "        print(f\"Models initialized!\")\n",
    "\n",
    "    # Move models to device (GPU/CPU)\n",
    "    generator.to(device)\n",
    "    discriminator.to(device)\n",
    "\n",
    "    # Loss functions from YAML\n",
    "    adversarial_loss = nn.BCEWithLogitsLoss()\n",
    "    content_loss = nn.L1Loss()   \n",
    "    lambda_l1 = config['training']['lambda_l1']\n",
    "\n",
    "    # Get optimizer from YAML configuration for both generator and discriminator\n",
    "    optimizer_G = get_optimizer(config['optimizer_G'], generator.parameters())\n",
    "    optimizer_D = get_optimizer(config['optimizer_D'], discriminator.parameters())\n",
    "\n",
    "    # Load optimizer state if available in checkpoint\n",
    "    if load_states:\n",
    "        if 'optimizer_gen_state_dict' in checkpoint and 'optimizer_disc_state_dict' in checkpoint:\n",
    "            optimizer_G.load_state_dict(checkpoint['optimizer_gen_state_dict'])\n",
    "            optimizer_D.load_state_dict(checkpoint['optimizer_disc_state_dict'])\n",
    "            print(\"Optimizer states loaded successfully!\")\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    mode = config['scheduler_G']['mode']\n",
    "    factor = config['scheduler_G']['factor']\n",
    "    patience = config['scheduler_G']['patience']\n",
    "    verbose = config['scheduler_G']['verbose']\n",
    "    scheduler_G = optim.lr_scheduler.ReduceLROnPlateau(optimizer_G, mode, factor, patience, verbose)\n",
    "\n",
    "    mode = config['scheduler_D']['mode']\n",
    "    factor = config['scheduler_D']['factor']\n",
    "    patience = config['scheduler_D']['patience']\n",
    "    verbose = config['scheduler_D']['verbose']\n",
    "    scheduler_D = optim.lr_scheduler.ReduceLROnPlateau(optimizer_D, mode, factor, patience, verbose)\n",
    "\n",
    "    # Number of epochs from YAML\n",
    "    epochs = config['training']['epochs']\n",
    "\n",
    "    # Flags for showing and saving images\n",
    "    show_fig = config['training']['show_fig']\n",
    "    save_images = config['training']['save_images']\n",
    "\n",
    "    # Initialize GANDriver with all parameters from YAML\n",
    "    driver = GANDriver(\n",
    "        generator=generator,\n",
    "        discriminator=discriminator,\n",
    "        train_dl=train_dl,\n",
    "        val_dl=val_dl,\n",
    "        optimizer_G=optimizer_G,\n",
    "        optimizer_D=optimizer_D,\n",
    "        adversarial_loss=adversarial_loss,\n",
    "        content_loss=content_loss,\n",
    "        lambda_l1=lambda_l1,\n",
    "        device=device,\n",
    "        epochs=epochs,\n",
    "        scheduler_D=scheduler_D, \n",
    "        scheduler_G=scheduler_G,\n",
    "        run_dir=config['output']['run_dir'],\n",
    "        base_dir=config['output']['base_dir']\n",
    "    )\n",
    "\n",
    "    # Run the GAN training and save metrics to CSV after each epoch\n",
    "    train_results = driver.run(show_fig=show_fig, save_images=save_images)\n",
    "\n",
    "    # Save training results to CSV\n",
    "    results_df = pd.DataFrame(train_results)\n",
    "    result_path = f\"{config['output']['base_dir']}/{config['output']['run_dir']}/{config['output']['training_results_csv']}\"\n",
    "    results_df.to_csv(result_path, index=False)\n",
    "    logging.info(f\"Training complete. Results saved to {result_path}.\")\n",
    "\n",
    "    \n",
    "    # Save the dictionary to a YAML file\n",
    "    yaml_filepath = f\"{config['output']['base_dir']}/{config['output']['run_dir']}/config.yml\"\n",
    "    with open(yaml_filepath, 'w') as file:\n",
    "        yaml.dump(config, file, default_flow_style=False)\n",
    "    \n",
    "    logging.info(f\"Configuration saved to {yaml_filepath}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2d860e-e532-4382-8afd-bdab86314aac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
