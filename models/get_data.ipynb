{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_colab = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from descriminator import Descriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coco_path = untar_data(URLs.COCO_SAMPLE)\n",
    "# coco_path = str(coco_path) + \"/train_sample\"\n",
    "coco_path = \"/Users/nelsonfarrell/.fastai/data/coco_sample/train_sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to data: /Users/nelsonfarrell/.fastai/data/coco_sample/train_sample\n"
     ]
    }
   ],
   "source": [
    "print(f\"Path to data: {coco_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 2000\n"
     ]
    }
   ],
   "source": [
    "paths = glob.glob(coco_path + \"/*.jpg\") # Grabbing all the image file names\n",
    "np.random.seed(123)\n",
    "paths_subset = np.random.choice(paths, 10_000, replace = False) # choosing 1000 images randomly\n",
    "rand_idxs = np.random.permutation(10_000)\n",
    "train_idxs = rand_idxs[:8000] # choosing the first 8000 as training set\n",
    "val_idxs = rand_idxs[8000:] # choosing last 2000 as validation set\n",
    "train_paths = paths_subset[train_idxs]\n",
    "val_paths = paths_subset[val_idxs]\n",
    "print(len(train_paths), len(val_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
    "for ax, img_path in zip(axes.flatten(), train_paths[0:16]):\n",
    "    ax.imshow(Image.open(img_path))\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 256\n",
    "class ColorizationDataset(Dataset):\n",
    "    def __init__(self, paths, split='train'):\n",
    "        if split == 'train':\n",
    "            self.transforms = transforms.Compose([\n",
    "                transforms.Resize((SIZE, SIZE),  Image.BICUBIC),\n",
    "                transforms.RandomHorizontalFlip(), # A little data augmentation!\n",
    "            ])\n",
    "        elif split == 'val':\n",
    "            self.transforms = transforms.Resize((SIZE, SIZE),  Image.BICUBIC)\n",
    "        \n",
    "        self.split = split\n",
    "        self.size = SIZE\n",
    "        self.paths = paths\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
    "        img = self.transforms(img)\n",
    "        img = np.array(img)\n",
    "        img_lab = rgb2lab(img).astype(\"float32\") # Converting RGB to L*a*b\n",
    "        img_lab = transforms.ToTensor()(img_lab)\n",
    "        L = (img_lab[[0], ...] / 50.) - 1. # Between -1 and 1\n",
    "        ab = img_lab[[1, 2], ...] / 110. # Between -1 and 1\n",
    "        \n",
    "        return {'L': L, 'ab': ab}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ColorizationDataset(paths = train_paths, split = \"train\")\n",
    "val_ds = ColorizationDataset(paths = val_paths, split = \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size = 16)\n",
    "val_dl = DataLoader(val_ds, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 256, 256]) torch.Size([16, 2, 256, 256])\n",
      "500 125\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(train_dl))\n",
    "Ls, abs_ = data['L'], data['ab']\n",
    "print(Ls.shape, abs_.shape)\n",
    "print(len(train_dl), len(val_dl))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1df5de7dcd6dcdadef7fe3c86013ee0233768960d04fd09831356728985397f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
